{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the XOR Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]\n",
    "             ])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36787944, 0.36787944, 0.36787944],\n",
       "       [0.36787944, 1.        , 0.36787944],\n",
       "       [1.        , 0.36787944, 0.36787944],\n",
       "       [1.        , 1.        , 0.36787944]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etzim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.58197671, 1.58197671, 1.58197671],\n",
       "       [1.58197671,        inf, 1.58197671],\n",
       "       [       inf, 1.58197671, 1.58197671],\n",
       "       [       inf,        inf, 1.58197671]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1 - np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "eta = 3\n",
    "\n",
    "# Number of epochs for learning\n",
    "epochs = 1000\n",
    "\n",
    "# Number of Hidden Neurons\n",
    "hidden = 15\n",
    "\n",
    "# Drop out rate probability (drp = 1 means no dropout)\n",
    "drp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(X,mode,k=drp):\n",
    "    # When training (mode=\"0\") Drop out applies for the hidden layer outputs a_h\n",
    "    if mode == 0:\n",
    "        #print(\"Testing mode activated\")\n",
    "        z_h = np.dot(X, w01)\n",
    "        a_h = sigmoid(z_h)\n",
    "        #print(\"a_h before drop out:\", a_h)\n",
    "        r = np.random.binomial(size=a_h.shape,n=1,p=k)\n",
    "        a_h *= r\n",
    "        #print(\"a_h AFTER drop out, a_h:\", a_h)\n",
    "        #print(\"\\n\")\n",
    "        z_o = np.dot(a_h, w12)\n",
    "        a_o = sigmoid(z_o)\n",
    "    \n",
    "    # When Testing (mode = \"1\") we use the normal weights w12 (not scaled with p)\n",
    "    elif mode == 1:\n",
    "        #print(\"Training mode activated\")\n",
    "        z_h = np.dot(X, w01)\n",
    "        a_h = sigmoid(z_h)\n",
    "        z_o = np.dot(a_h, w12)\n",
    "        a_o = sigmoid(z_o)\n",
    "    else:\n",
    "        print(\"Must specify 2nd argument '0' for Training or '1' for Test\")\n",
    "        \n",
    "    return(a_o,a_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = np.random.rand(*a_h.shape) < drp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.shape\n",
    "#a_h*test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w01 = np.random.random((len(X[0]), hidden))\n",
    "w12 = np.random.random((hidden, 1))\n",
    "\n",
    "w01_list = []\n",
    "w12_list = []\n",
    "#r = np.random.binomial(size=a_h.shape, n=1, p= 0.5)\n",
    "#r.shape\n",
    "#w12.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start feeding forward and backpropagate *epochs* times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_o = []\n",
    "for epoch in range(epochs):\n",
    "    if drp == 0.5:\n",
    "        a_o, a_h = feedforward(X,0,drp)\n",
    "\n",
    "        # Calculate the error\n",
    "        a_o_error = ((1 / 2) * (np.power((a_o - y), 2)))\n",
    "        #print(\"******** Error after \", epoch, \"epochs is \", sum(a_o_error), \"*********\")\n",
    "        #print(sum(a_o_error))\n",
    "        E_o = np.append(E_o, sum(a_o_error))\n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "        ## Output to Hidden Layer weights\n",
    "        delta_E_o = a_o - y\n",
    "        delta_a_o = sigmoid(a_o,derivative=True)\n",
    "        delta_z_o = a_h\n",
    "        delta_E_w12 = np.dot(delta_z_o.T,(delta_E_o * delta_a_o))\n",
    "\n",
    "\n",
    "        ## Hidden to Input Layer weights\n",
    "        delta_E_h = np.dot(delta_E_o * delta_a_o, w12.T)\n",
    "        delta_a_h = sigmoid(a_h,derivative=True)\n",
    "        delta_z_h = X\n",
    "        delta_E_w01 = np.dot(delta_z_h.T, delta_E_h * delta_a_h)\n",
    "\n",
    "\n",
    "        # Store All weights throughout learning\n",
    "        w01_list.append(w01)\n",
    "        w12_list.append(w12)\n",
    "\n",
    "        # Adjust weights\n",
    "        w01 = w01 - eta * delta_E_w01\n",
    "        w12 = w12 - eta * delta_E_w12\n",
    "        \n",
    "    elif drp == 1:\n",
    "        a_o, a_h = feedforward(X,0,drp)\n",
    "    \n",
    "        # Calculate the error\n",
    "        a_o_error = ((1 / 2) * (np.power((a_o - y), 2)))\n",
    "        #print(\"******** Error after \", epoch, \"epochs is \", sum(a_o_error), \"*********\")\n",
    "        #print(sum(a_o_error))\n",
    "        E_o = np.append(E_o, sum(a_o_error))\n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "        ## Output to Hidden Layer weights\n",
    "        delta_E_o = a_o - y\n",
    "        delta_a_o = sigmoid(a_o,derivative=True)\n",
    "        delta_z_o = a_h\n",
    "        delta_E_w12 = np.dot(delta_z_o.T,(delta_E_o * delta_a_o))\n",
    "\n",
    "\n",
    "        ## Hidden to Input Layer weights\n",
    "        delta_E_h = np.dot(delta_E_o * delta_a_o, w12.T)\n",
    "        delta_a_h = sigmoid(a_h,derivative=True)\n",
    "        delta_z_h = X\n",
    "        delta_E_w01 = np.dot(delta_z_h.T, delta_E_h * delta_a_h)\n",
    "\n",
    "\n",
    "        # Store All weights throughout learning\n",
    "        w01_list.append(w01)\n",
    "        w12_list.append(w12)\n",
    "\n",
    "        # Adjust weights\n",
    "        w01 = w01 - eta * delta_E_w01\n",
    "        w12 = w12 - eta * delta_E_w12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_h_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking dimensions across calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"\")\n",
    "    print(\"E_o dimension is \", delta_E_o.shape)\n",
    "    print(\"delta_a_o dimension is \", delta_a_o.shape)\n",
    "    print(\"delta_z_o dimension is \", delta_z_o.shape)\n",
    "    print(\"delta_E_o times delta_a_o dimension is \", (delta_E_o * delta_a_o).shape)\n",
    "    print(\"delta_z_o Transpose dimension is\", (delta_z_o.T).shape)\n",
    "    print(\"Output layer dimension is \", delta_E_w12.shape)\n",
    "    print(\"\")\n",
    "    print(\"delta_E_o times delta_a_o dimension is \", (delta_E_o * delta_a_o).shape)\n",
    "    print(\"w12 Transpose dimension is\", (w12.T).shape)    \n",
    "    print(\"delta_E_h dimension is \", delta_E_h.shape)\n",
    "    print(\"delta_a_h dimension is \", delta_a_h.shape)\n",
    "    print(\"delta_z_h dimension is \", delta_z_h.shape)\n",
    "    print(\"Hidden Layer dimension is \", delta_E_w01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_h.shape\n",
    "#r.shape\n",
    "#r = np.random.binomial(size=a_h.shape,n=1,p=drp)\n",
    "#r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through Epochs and storing learned weights evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w01_curve = []\n",
    "for i in range(w01.shape[0]):\n",
    "    for j in range(w01.shape[1]):\n",
    "        for x in range(len(w01_list)):\n",
    "            #print(w01_list[x][i][j])\n",
    "            w01_curve.append(w01_list[x][i][j])\n",
    "            #print(\"Weights w[\",x,\"],[\",i,\"],[\",j,\"] stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting weights as the NN learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "numberOfWeights = w01.shape[1]*w01.shape[0]\n",
    "for k in range(numberOfWeights):\n",
    "    t= w01_curve[(epochs*k):(epochs*(k+1)-1)]\n",
    "    plt.plot(t)\n",
    "\n",
    "fig.suptitle('W01 Weights learning', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('W01', fontsize=12)\n",
    "fig.savefig('W01_curve.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input-Hidden Layer weights w01:\\n\",w01)\n",
    "print(\"\\nHidden-Output Layer weights w12:\\n\",w12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Error curve - Plot & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if drp == 1: \n",
    "    print(\"Minimum Error achieved:\", min(E_o)) \n",
    "    print(\"Epochs run:\", epochs)\n",
    "    print(\"Hidden neurons\",hidden)\n",
    "    print(\"Learning Rate:\",eta)\n",
    "    np.savetxt(\"Error_nD.csv\", E_o, delimiter=\",\")\n",
    "    fig = plt.figure()\n",
    "    plt.plot(E_o)\n",
    "    fig.suptitle('Error without Dropout', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Error', fontsize=12)\n",
    "    fig.savefig('Error_nD.jpg')\n",
    "    plt.show()\n",
    "\n",
    "elif drp == 0.5:\n",
    "    print(\"Minimum Error achieved:\", min(E_o)) \n",
    "    print(\"Epochs run:\", epochs)\n",
    "    print(\"Hidden neurons\",hidden)\n",
    "    print(\"Learning Rate:\",eta)\n",
    "    np.savetxt(\"Error_D.csv\", E_o, delimiter=\",\")\n",
    "    fig = plt.figure()\n",
    "    plt.plot(E_o)\n",
    "    fig.suptitle('Error with Dropout', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Error', fontsize=12)\n",
    "    fig.savefig('Error_D.jpg')\n",
    "    plt.show()\n",
    "\n",
    "else: \n",
    "    print(\"No valid value for Drop out Hyperparameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Run: Learned XOR Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drp == 1:\n",
    "    a_o, a_h = feedforward(X,1)\n",
    "    np.savetxt(\"Predicted_Output_nD.csv\", a_o, delimiter=\",\")\n",
    "    #print(\"Predicted output:\", a_o)\n",
    "elif drp == 0.5:\n",
    "    a_o, a_h = feedforward(X,1)\n",
    "    np.savetxt(\"Predicted_Output_D.csv\", a_o, delimiter=\",\")\n",
    "    #print(\"Predicted output:\", a_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Error_nD = genfromtxt('Error_nD.csv', delimiter=',') \n",
    "Error_D = genfromtxt('Error_D.csv', delimiter=',')\n",
    "Pred_nD = genfromtxt('Predicted_Output_nD.csv', delimiter=',')\n",
    "Pred_D = genfromtxt('Predicted_Output_D.csv', delimiter=',')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(Error_D)\n",
    "plt.plot(Error_nD)\n",
    "fig.suptitle('Error Diff', fontsize=16)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Error achieved', fontsize=12)\n",
    "fig.savefig('Error Diff.jpg')\n",
    "plt.show()\n",
    "\n",
    "print(\"Error without Dropoff\", min(Error_nD))\n",
    "print(\"Predicted output without Dropoff:\", Pred_nD)\n",
    "print(\"\\nError with Dropoff\", min(Error_D))\n",
    "print(\"Predicted output with Dropoff:\", Pred_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
